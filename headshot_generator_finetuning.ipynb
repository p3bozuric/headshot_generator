{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1jPJXI8W4R7jocXzCDPT8_BnBwil1RgOs",
      "authorship_tag": "ABX9TyPCpNFGJQv5NewHKaiaw77b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25ea220a138c4688b16a10cbadfc2ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f91162ba06d64063a1e6a4c264e132e7",
              "IPY_MODEL_34cd8ca235ce4747a3aa72dd61777127",
              "IPY_MODEL_fe11f8293d664a2eae55ea5cc05bbcb2"
            ],
            "layout": "IPY_MODEL_d2ebf8d301be4f2786c749f56ea346d1"
          }
        },
        "f91162ba06d64063a1e6a4c264e132e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da16d067e4c4509a20c4c3268150a1b",
            "placeholder": "​",
            "style": "IPY_MODEL_aafc0b03639c4057878fd012be5be20a",
            "value": ""
          }
        },
        "34cd8ca235ce4747a3aa72dd61777127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2454e62a48a44d2cbf6d87172b90f1f6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4294dc8779048febee58300ca576f87",
            "value": 0
          }
        },
        "fe11f8293d664a2eae55ea5cc05bbcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ceeb8a42524a0dbe33dfb1dfeb720b",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a89a6d5e454e12ab995771dec6dda7",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "d2ebf8d301be4f2786c749f56ea346d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da16d067e4c4509a20c4c3268150a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aafc0b03639c4057878fd012be5be20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2454e62a48a44d2cbf6d87172b90f1f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d4294dc8779048febee58300ca576f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85ceeb8a42524a0dbe33dfb1dfeb720b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a89a6d5e454e12ab995771dec6dda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p3bozuric/headshot_generator/blob/main/headshot_generator_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is no-code tuning for headshot generator AI model.\n",
        "\n",
        "This notebook is build to be run in Google Colab.\n",
        "\n",
        "A100 GPU would be optimal for running this training. Depending on settings you set it will take a couple of hours. Make sure you keep this session running."
      ],
      "metadata": {
        "id": "GQmwkS-qido_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Giving access to Google Drive\n",
        "\n",
        "Manual approval to Google is mandatory after running next cell.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Irh19UjFwUMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2A18WKc7-JvB",
        "collapsed": true,
        "outputId": "97576caf-9bbe-446e-f196-f4f75a1fa3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing AI toolkit environment"
      ],
      "metadata": {
        "id": "fOeTEUzmxJCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6NEClUz8xXR",
        "outputId": "ac17447e-3114-49a2-f562-d96cdb05058c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai-toolkit'...\n",
            "remote: Enumerating objects: 3911, done.\u001b[K\n",
            "remote: Counting objects: 100% (3910/3910), done.\u001b[K\n",
            "remote: Compressing objects: 100% (974/974), done.\u001b[K\n",
            "remote: Total 3911 (delta 2987), reused 3725 (delta 2848), pack-reused 1 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3911/3911), 29.65 MiB | 26.96 MiB/s, done.\n",
            "Resolving deltas: 100% (2987/2987), done.\n",
            "Note: switching to '86b5938cf35bde7b1eab33a001515433b01a7b63'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 86b5938 Fixed the webp bug finally.\n",
            "Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n",
            "Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n",
            "Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n",
            "Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator'...\n",
            "Cloning into '/content/ai-toolkit/repositories/ipadapter'...\n",
            "Cloning into '/content/ai-toolkit/repositories/leco'...\n",
            "Cloning into '/content/ai-toolkit/repositories/sd-scripts'...\n",
            "Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n",
            "Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n",
            "Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n",
            "Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n",
            "Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n",
            "Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-ebphyzjc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-ebphyzjc\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit b821f006d025b72654223b32e6bf0c49afed371d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.1+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.44.2)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 7))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Collecting oyaml (from -r requirements.txt (line 9))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.17.0)\n",
            "Collecting kornia (from -r requirements.txt (line 11))\n",
            "  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 12))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.8.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.34.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Requirement already satisfied: albumentations==1.4.15 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.4.15)\n",
            "Requirement already satisfied: albucore==0.0.16 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.0.16)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.9.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 19))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 20))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 21))\n",
            "  Downloading open_clip_torch-2.27.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.0.10)\n",
            "Collecting prodigyopt (from -r requirements.txt (line 23))\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n",
            "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv (from -r requirements.txt (line 25))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 26))\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting hf_transfer (from -r requirements.txt (line 27))\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting lpips (from -r requirements.txt (line 28))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 29))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto (from -r requirements.txt (line 30))\n",
            "  Downloading optimum_quanto-0.2.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.24.7)\n",
            "Collecting peft (from -r requirements.txt (line 33))\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 34))\n",
            "  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (8.0.4)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.24.0)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (10.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (4.66.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.0.4)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n",
            "  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible-watermark->-r requirements.txt (line 12))\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.23.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->-r requirements.txt (line 20)) (0.18.3)\n",
            "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n",
            "  Downloading ftfy-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting ninja (from optimum-quanto->-r requirements.txt (line 30))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface_hub (from -r requirements.txt (line 32))\n",
            "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading orjson-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.2.2)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.12.5)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio->-r requirements.txt (line 34))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
            "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio->-r requirements.txt (line 34))\n",
            "  Downloading starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 34))\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.20.2)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (2.2.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (2.16.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (1.3.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.20.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n",
            "Downloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.3/833.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-2.27.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading optimum_quanto-0.2.5-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.1.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading orjson-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.7.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading ftfy-6.3.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.40.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lycoris-lora, controlnet_aux, diffusers, antlr4-python3-runtime\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77134 sha256=7e612735873e83445cbc6f6d701f1d09f76353db9a83a666583e95d7843197e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n",
            "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274344 sha256=db35c133f88d663778b8e6aa80d7c98381ff454035b152c2286624253ed1dada\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.31.0.dev0-py3-none-any.whl size=2870477 sha256=7b8646d1b5c14ec23ab838f88419c9797c6cfffc93b36045a4d5559e639af970\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d7sh3di8/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=61356a0bee64f5eb3062c88559e12962f86cffd9173c9dd68ea3949f5427655e\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built lycoris-lora controlnet_aux diffusers antlr4-python3-runtime\n",
            "Installing collected packages: trampoline, pydub, ninja, antlr4-python3-runtime, websockets, tomlkit, semantic-version, ruff, PyWavelets, python-multipart, python-dotenv, prodigyopt, oyaml, orjson, omegaconf, markupsafe, kornia-rs, hf_transfer, h11, ftfy, flatten_json, ffmpy, aiofiles, uvicorn, starlette, huggingface_hub, httpcore, httpx, fastapi, diffusers, torchsde, torchdiffeq, optimum-quanto, kornia, jsonmerge, invisible-watermark, gradio-client, dctorch, bitsandbytes, pytorch_fid, peft, lycoris-lora, lpips, gradio, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.1\n",
            "    Uninstalling MarkupSafe-3.0.1:\n",
            "      Successfully uninstalled MarkupSafe-3.0.1\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.30.3\n",
            "    Uninstalling diffusers-0.30.3:\n",
            "      Successfully uninstalled diffusers-0.30.3\n",
            "Successfully installed PyWavelets-1.7.0 aiofiles-23.2.1 antlr4-python3-runtime-4.9.3 bitsandbytes-0.44.1 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.31.0.dev0 fastapi-0.115.2 ffmpy-0.4.0 flatten_json-0.1.14 ftfy-6.3.0 gradio-5.1.0 gradio-client-1.4.0 h11-0.14.0 hf_transfer-0.1.8 httpcore-1.0.6 httpx-0.27.2 huggingface_hub-0.26.1 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.7.3 kornia-rs-0.1.5 lpips-0.1.4 lycoris-lora-1.8.3 markupsafe-2.1.5 ninja-1.11.1.1 omegaconf-2.3.0 open_clip_torch-2.27.1 optimum-quanto-0.2.5 orjson-3.10.9 oyaml-1.0 peft-0.13.2 prodigyopt-1.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.12 pytorch_fid-0.3.0 ruff-0.7.0 semantic-version-2.10.0 starlette-0.40.0 tomlkit-0.12.0 torchdiffeq-0.2.4 torchsde-0.2.6 trampoline-0.1.2 uvicorn-0.32.0 websockets-12.0\n",
            "Collecting optimum-quanto==0.2.4\n",
            "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from optimum-quanto==0.2.4) (2.4.1+cu121)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from optimum-quanto==0.2.4) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum-quanto==0.2.4) (1.26.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from optimum-quanto==0.2.4) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->optimum-quanto==0.2.4) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->optimum-quanto==0.2.4) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->optimum-quanto==0.2.4) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->optimum-quanto==0.2.4) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->optimum-quanto==0.2.4) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->optimum-quanto==0.2.4) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->optimum-quanto==0.2.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->optimum-quanto==0.2.4) (1.3.0)\n",
            "Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optimum-quanto\n",
            "  Attempting uninstall: optimum-quanto\n",
            "    Found existing installation: optimum-quanto 0.2.5\n",
            "    Uninstalling optimum-quanto-0.2.5:\n",
            "      Successfully uninstalled optimum-quanto-0.2.5\n",
            "Successfully installed optimum-quanto-0.2.4\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.10)\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.26.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.10\n",
            "    Uninstalling timm-1.0.10:\n",
            "      Successfully uninstalled timm-1.0.10\n",
            "Successfully installed timm-1.0.11\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ostris/ai-toolkit.git\n",
        "!cd /content/ai-toolkit && git checkout 86b5938cf35bde7b1eab33a001515433b01a7b63\n",
        "!cd /content/ai-toolkit && git submodule update --init --recursive\n",
        "!cd /content/ai-toolkit && pip install -r requirements.txt\n",
        "!pip install optimum-quanto==0.2.4\n",
        "!pip install -U --no-cache-dir timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huggingface token preparation (HF_TOKEN)\n",
        "\n",
        "How to get & prepare HF_TOKEN:\n",
        "1. Log in to huggingface\n",
        "2. Create a token here: https://huggingface.co/settings/tokens\n",
        "3. You need to click on the key icon to the left and place your token there under the name 'HF_TOKEN'."
      ],
      "metadata": {
        "id": "Qjd2AsPayKqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqnWX3Ct85c6",
        "outputId": "c6c8ff65-e562-4275-97e5-cc5d644d4524"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing packages\n"
      ],
      "metadata": {
        "id": "7m2bbTqNyZ2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ],
      "metadata": {
        "id": "5juDfccJ85YR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation\n",
        "\n",
        "1. Dataset needs to be in folder **flux_dataset** which is inside of output directory you set in next cell.\n",
        "\n",
        "2. Dataset needs to have 20-30 images of your face from different angles and backgrounds in various situations and face expressions.\n",
        "\n",
        "3. Images should have names like: image001.jpg\n",
        "\n",
        "4. Corresponding .txt files explaining the content of those images should be named like so: image001.txt\n",
        "\n",
        "Keep in mind that .txt files are not necessary, but fine tuning will be better with written content of images."
      ],
      "metadata": {
        "id": "_-OsDNyZco3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter setup\n",
        "\n",
        "Fill out the form and run the cell.\n"
      ],
      "metadata": {
        "id": "iflHiGvMy16X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown ## **Project Configuration**\n",
        "#@markdown Title of your project\n",
        "project_name = 'professional_headshot_generator' # @param {type:\"string\"}\n",
        "#@markdown Model you'll be fine-tuning. This code is optimized for FLUX.1-dev.\n",
        "model_name = 'black-forest-labs/FLUX.1-dev' # @param [\"black-forest-labs/FLUX.1-dev\"]\n",
        "#@markdown Where you want your model to be saved at. Keep in mind \"/content/drive/MyDrive/\" should be a constant.\n",
        "output_dir = '/content/drive/MyDrive/headshot-generator' # @param {type:\"string\"}\n",
        "#@markdown Instance prompt is a unique code by which you refer to yourself when prompting the generator in the inference.\n",
        "instance_prompt = \"pa3k\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## **Training Configuration**\n",
        "#@markdown These parameters control the training process of your model.\n",
        "\n",
        "#@markdown Number of images processed in one iteration.\n",
        "batch_size = 2 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Total number of training iterations. 1000-4000 is a good range.\n",
        "total_steps = 2000 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Rate at which the model learns. Higher values may lead to faster learning but potential instability.\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "\n",
        "#@markdown Image resolutions to use during training. FLUX model benefits from multiple resolutions.\n",
        "resolution = [512, 768, 1024] # @param {type:\"raw\"}\n",
        "\n",
        "#@markdown Whether to train the U-Net part of the model. Usually kept True.\n",
        "train_unet = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Whether to train the text encoder. Usually False for FLUX models.\n",
        "train_text_encoder = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Use 8-bit Adam optimizer for reduced memory usage. Recommended if your GPU supports it.\n",
        "use_8bit_adam = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Saves memory by doing forward/backward passes in chunks. Needed unless you have a lot of VRAM.\n",
        "use_gradient_checkpointing = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Use Exponential Moving Average for more stable training. Recommended to leave on.\n",
        "use_ema = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown EMA decay rate. Higher values give more weight to recent iterations. Best to leave at 0.99.\n",
        "ema_decay = 0.99 # @param {type:\"number\"}\n",
        "\n",
        "#@markdown Use bfloat16 precision. Speeds up training if your GPU supports it.\n",
        "use_bf16 = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## **Sampling Configuration**\n",
        "#@markdown These settings control the generation of test images during the training process.\n",
        "\n",
        "#@markdown Generate sample images every this many steps.\n",
        "sample_every = 500 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Width of the generated sample images.\n",
        "sample_width = 1024 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Height of the generated sample images.\n",
        "sample_height = 1024 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown How closely the image adheres to the prompt. Higher values = closer adherence.\n",
        "guidance_scale = 4 # @param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of denoising steps in image generation. More steps = potentially higher quality but slower.\n",
        "sample_steps = 40 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## **Advanced Configuration**\n",
        "#@markdown These are additional parameters for fine-tuning the training process.\n",
        "\n",
        "#@markdown Log performance stats in the terminal every N steps\n",
        "performance_log_every = 500 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Device to use for training\n",
        "device = 'cuda:0' # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Linear layer rank for LoRA\n",
        "lora_rank = 16 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Linear layer alpha value for LoRA\n",
        "lora_alpha = 16 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Precision to save the model\n",
        "save_precision = 'float16' # @param [\"float16\", \"float32\"]\n",
        "\n",
        "#@markdown Save the model every this many steps\n",
        "save_every = 500 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Number of intermittent saves to keep\n",
        "max_save_keeps = 4 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Rate at which captions are dropped during training\n",
        "caption_dropout_rate = 0.05 # @param {type:\"number\"}\n",
        "\n",
        "#@markdown Whether to shuffle tokens in captions\n",
        "shuffle_caption_tokens = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Cache latents to disk for faster loading\n",
        "cache_latents = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Number of gradient accumulation steps\n",
        "gradient_accumulation_steps = 2 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Training focus: content, style, or balanced\n",
        "content_or_style = 'content' # @param [\"content\", \"style\", \"balanced\"]\n",
        "\n",
        "#@markdown Noise scheduler to use during training\n",
        "noise_scheduler = 'flowmatch' # @param [\"flowmatch\", \"ddpm\", \"ddim\"]\n",
        "\n",
        "#@markdown Skip the first sample generation\n",
        "skip_first_sample = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Whether the model is a FLUX model\n",
        "is_flux_model = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Use 8-bit quantization\n",
        "use_quantization = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Use low VRAM mode (slower but uses less memory)\n",
        "low_vram_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Sampler to use for generating samples\n",
        "sample_sampler = 'flowmatch' # @param [\"flowmatch\", \"ddpm\", \"ddim\"]\n",
        "\n",
        "#@markdown Seed for random number generation\n",
        "random_seed = 42 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Whether to use different seeds for each sample\n",
        "walk_seed = True # @param {type:\"boolean\"}\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "job_to_run = OrderedDict([\n",
        "    ('job', 'extension'),\n",
        "    ('config', OrderedDict([\n",
        "        ('name', project_name),\n",
        "        ('process', [\n",
        "            OrderedDict([\n",
        "                ('type', 'sd_trainer'),\n",
        "                ('training_folder', output_dir),\n",
        "                ('performance_log_every', performance_log_every),\n",
        "                ('device', device),\n",
        "                ('trigger_word', instance_prompt),\n",
        "                ('network', OrderedDict([\n",
        "                    ('type', 'lora'),\n",
        "                    ('linear', lora_rank),\n",
        "                    ('linear_alpha', lora_alpha)\n",
        "                ])),\n",
        "                ('save', OrderedDict([\n",
        "                    ('dtype', save_precision),\n",
        "                    ('save_every', save_every),\n",
        "                    ('max_step_saves_to_keep', max_save_keeps)\n",
        "                ])),\n",
        "                ('datasets', [\n",
        "                    OrderedDict([\n",
        "                        ('folder_path', f'{output_dir}/flux_dataset'),\n",
        "                        ('caption_ext', \"txt\"),\n",
        "                        ('caption_dropout_rate', caption_dropout_rate),\n",
        "                        ('shuffle_tokens', shuffle_caption_tokens),\n",
        "                        ('cache_latents_to_disk', cache_latents),\n",
        "                        ('resolution', resolution)\n",
        "                    ])\n",
        "                ]),\n",
        "                ('train', OrderedDict([\n",
        "                    ('batch_size', batch_size),\n",
        "                    ('steps', total_steps),\n",
        "                    ('gradient_accumulation_steps', gradient_accumulation_steps),\n",
        "                    ('train_unet', train_unet),\n",
        "                    ('train_text_encoder', train_text_encoder),\n",
        "                    ('content_or_style', content_or_style),\n",
        "                    ('gradient_checkpointing', use_gradient_checkpointing),\n",
        "                    ('noise_scheduler', noise_scheduler),\n",
        "                    ('optimizer', 'adamw8bit' if use_8bit_adam else 'adamw'),\n",
        "                    ('lr', learning_rate),\n",
        "                    ('skip_first_sample', skip_first_sample),\n",
        "                    ('ema_config', OrderedDict([\n",
        "                        ('use_ema', use_ema),\n",
        "                        ('ema_decay', ema_decay)\n",
        "                    ])),\n",
        "                    ('dtype', 'bf16' if use_bf16 else 'float32')\n",
        "                ])),\n",
        "                ('model', OrderedDict([\n",
        "                    ('name_or_path', model_name),\n",
        "                    ('is_flux', is_flux_model),\n",
        "                    ('quantize', use_quantization),\n",
        "                    ('low_vram', low_vram_mode),\n",
        "                ])),\n",
        "                ('sample', OrderedDict([\n",
        "                    ('sampler', sample_sampler),\n",
        "                    ('sample_every', sample_every),\n",
        "                    ('width', sample_width),\n",
        "                    ('height', sample_height),\n",
        "                    ('prompts', [\n",
        "                        f'professional headshot of {instance_prompt} in a suit, studio lighting, neutral background',\n",
        "                        f'business portrait of {instance_prompt} smiling, office setting, soft lighting',\n",
        "                        f'corporate headshot of {instance_prompt} with confident expression, blurred office background',\n",
        "                        f'professional profile picture of {instance_prompt} in business casual attire, outdoors',\n",
        "                        f'LinkedIn profile photo of {instance_prompt} with friendly expression, solid color background',\n",
        "                        f'{instance_prompt} giving a presentation in a conference room, professional attire',\n",
        "                        f'close-up portrait of {instance_prompt} for company website, modern office background',\n",
        "                        f'{instance_prompt} in a casual business meeting, gesturing while speaking, natural light'\n",
        "                    ]),\n",
        "                    ('neg', ''),\n",
        "                    ('seed', random_seed),\n",
        "                    ('walk_seed', walk_seed),\n",
        "                    ('guidance_scale', guidance_scale),\n",
        "                    ('sample_steps', sample_steps)\n",
        "                ]))\n",
        "            ])\n",
        "        ])\n",
        "    ])),\n",
        "    ('meta', OrderedDict([\n",
        "        ('name', project_name),\n",
        "        ('version', '1.0')\n",
        "    ]))\n",
        "])"
      ],
      "metadata": {
        "id": "-lPm1YbL85Tn",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start the training with cell bellow when you're ready\n",
        "\n",
        "This might take a while. Keep the session running while training."
      ],
      "metadata": {
        "id": "x1ZAfsbrzJA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_job(job_to_run)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "25ea220a138c4688b16a10cbadfc2ff3",
            "f91162ba06d64063a1e6a4c264e132e7",
            "34cd8ca235ce4747a3aa72dd61777127",
            "fe11f8293d664a2eae55ea5cc05bbcb2",
            "d2ebf8d301be4f2786c749f56ea346d1",
            "2da16d067e4c4509a20c4c3268150a1b",
            "aafc0b03639c4057878fd012be5be20a",
            "2454e62a48a44d2cbf6d87172b90f1f6",
            "d4294dc8779048febee58300ca576f87",
            "85ceeb8a42524a0dbe33dfb1dfeb720b",
            "a1a89a6d5e454e12ab995771dec6dda7"
          ]
        },
        "id": "UERlMZQV85Kk",
        "outputId": "238535a2-c94b-4fd7-e56e-b8060ce07365",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25ea220a138c4688b16a10cbadfc2ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/content/ai-toolkit/extensions_built_in/sd_trainer/SDTrainer.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"type\": \"sd_trainer\",\n",
            "    \"training_folder\": \"/content/drive/MyDrive/headshot-generator\",\n",
            "    \"performance_log_every\": 500,\n",
            "    \"device\": \"cuda:0\",\n",
            "    \"trigger_word\": \"pa3k\",\n",
            "    \"network\": {\n",
            "        \"type\": \"lora\",\n",
            "        \"linear\": 16,\n",
            "        \"linear_alpha\": 16\n",
            "    },\n",
            "    \"save\": {\n",
            "        \"dtype\": \"float16\",\n",
            "        \"save_every\": 500,\n",
            "        \"max_step_saves_to_keep\": 4\n",
            "    },\n",
            "    \"datasets\": [\n",
            "        {\n",
            "            \"folder_path\": \"/content/drive/MyDrive/headshot-generator/flux_dataset\",\n",
            "            \"caption_ext\": \"txt\",\n",
            "            \"caption_dropout_rate\": 0.05,\n",
            "            \"shuffle_tokens\": false,\n",
            "            \"cache_latents_to_disk\": true,\n",
            "            \"resolution\": [\n",
            "                512,\n",
            "                768,\n",
            "                1024\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"train\": {\n",
            "        \"batch_size\": 2,\n",
            "        \"steps\": 2000,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"train_unet\": true,\n",
            "        \"train_text_encoder\": false,\n",
            "        \"content_or_style\": \"content\",\n",
            "        \"gradient_checkpointing\": true,\n",
            "        \"noise_scheduler\": \"flowmatch\",\n",
            "        \"optimizer\": \"adamw8bit\",\n",
            "        \"lr\": 0.0001,\n",
            "        \"skip_first_sample\": true,\n",
            "        \"ema_config\": {\n",
            "            \"use_ema\": true,\n",
            "            \"ema_decay\": 0.99\n",
            "        },\n",
            "        \"dtype\": \"bf16\"\n",
            "    },\n",
            "    \"model\": {\n",
            "        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
            "        \"is_flux\": true,\n",
            "        \"quantize\": true,\n",
            "        \"low_vram\": false\n",
            "    },\n",
            "    \"sample\": {\n",
            "        \"sampler\": \"flowmatch\",\n",
            "        \"sample_every\": 500,\n",
            "        \"width\": 1024,\n",
            "        \"height\": 1024,\n",
            "        \"prompts\": [\n",
            "            \"professional headshot of pa3k in a suit, studio lighting, neutral background\",\n",
            "            \"business portrait of pa3k smiling, office setting, soft lighting\",\n",
            "            \"corporate headshot of pa3k with confident expression, blurred office background\",\n",
            "            \"professional profile picture of pa3k in business casual attire, outdoors\",\n",
            "            \"LinkedIn profile photo of pa3k with friendly expression, solid color background\",\n",
            "            \"pa3k giving a presentation in a conference room, professional attire\",\n",
            "            \"close-up portrait of pa3k for company website, modern office background\",\n",
            "            \"pa3k in a casual business meeting, gesturing while speaking, natural light\"\n",
            "        ],\n",
            "        \"neg\": \"\",\n",
            "        \"seed\": 42,\n",
            "        \"walk_seed\": true,\n",
            "        \"guidance_scale\": 4,\n",
            "        \"sample_steps\": 40\n",
            "    }\n",
            "}\n",
            "Using EMA\n",
            "\n",
            "#############################################\n",
            "# Running job: professional_headshot_generator\n",
            "#############################################\n",
            "\n",
            "\n",
            "Running  1 process\n",
            "Loading Flux model\n",
            "Loading transformer\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8519949f2c4c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_to_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ai-toolkit/toolkit/job.py\u001b[0m in \u001b[0;36mrun_job\u001b[0;34m(config, name)\u001b[0m\n\u001b[1;32m     41\u001b[0m ):\n\u001b[1;32m     42\u001b[0m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ai-toolkit/jobs/ExtensionJob.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ai-toolkit/jobs/process/BaseSDTrainProcess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         )\n\u001b[1;32m   1240\u001b[0m         \u001b[0;31m# run base sd process run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_torch_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ai-toolkit/toolkit/stable_diffusion_model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mbase_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             transformer = FluxTransformer2DModel.from_pretrained(\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0mtransformer_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# load config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         config, unused_kwargs, commit_hash = cls.load_config(\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 config_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    380\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid repo type: {repo_type}. Accepted repo types are: {str(constants.REPO_TYPES)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     headers = build_hf_headers(\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, is_write_action, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Get auth token to send\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mtoken_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0m_validate_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_write_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_write_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mget_token_to_send\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# Token is not provided: we get it from local cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mcached_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# Case token is explicitly required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py\u001b[0m in \u001b[0;36mget_token\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_token_from_google_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_token_from_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_token_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py\u001b[0m in \u001b[0;36m_get_token_from_google_colab\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0m_GOOGLE_COLAB_SECRET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;31m# thread-safe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_userdata_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     resp = _message.blocking_request(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;34m'GetSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}